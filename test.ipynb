{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on pima.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7         8\n",
       "0     6  148  72  35    0  33.6  0.627  50  positive\n",
       "1     1   85  66  29    0  26.6  0.351  31  negative\n",
       "2     8  183  64   0    0  23.3  0.672  32  positive\n",
       "3     1   89  66  23   94  28.1  0.167  21  negative\n",
       "4     0  137  40  35  168  43.1  2.288  33  positive\n",
       "..   ..  ...  ..  ..  ...   ...    ...  ..       ...\n",
       "763  10  101  76  48  180  32.9  0.171  63  negative\n",
       "764   2  122  70  27    0  36.8  0.340  27  negative\n",
       "765   5  121  72  23  112  26.2  0.245  30  negative\n",
       "766   1  126  60   0    0  30.1  0.349  47  positive\n",
       "767   1   93  70  31    0  30.4  0.315  23  negative\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"pima.txt\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "df['label'] = df[df.shape[1] - 1]\n",
    "df.drop([df.shape[1] - 2], axis=1, inplace=True)\n",
    "labelencoder = LabelEncoder()\n",
    "df['label'] = labelencoder.fit_transform(df['label'])\n",
    "x = np.array(df.drop(['label'], axis=1))\n",
    "y = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalization_object = Normalizer()\n",
    "X = normalization_object.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cusboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ROC:  0.7524416491963661  Aupr:  0.6266355860757725  for depth=  2  estimators =  20\n",
      "Result: ROC:  0.7524416491963661  Aupr:  0.6266355860757725  for depth=  2  estimators =  20\n",
      "Result: ROC:  0.7554828791055206  Aupr:  0.5851593865045149  for depth=  2  estimators =  40\n",
      "Result: ROC:  0.9098294898672258  Aupr:  0.8593509589017245  for depth=  12  estimators =  20\n",
      "Result: ROC:  0.9194570230607966  Aupr:  0.8575327778697035  for depth=  12  estimators =  30\n",
      "Result: ROC:  0.9244252271139064  Aupr:  0.86429099336812  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        tprs = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train = X[train_index]\n",
    "            X_test = X[test_index]\n",
    "            y_train = y[train_index]\n",
    "            y_test = y[test_index]\n",
    "            classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "            classifier.fit(X, y)\n",
    "            predictions = classifier.predict_proba_samme(X_test)\n",
    "            auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "            aupr = average_precision_score(y_test, predictions[:, 1])\n",
    "            current_param_auc.append(auc)\n",
    "            current_param_aupr.append(aupr)\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "            tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        if top_auc < current_mean_auc:\n",
    "            top_auc = current_mean_auc\n",
    "            best_depth = depth\n",
    "            best_estimators = estimators\n",
    "            best_auc = top_auc\n",
    "            best_aupr = current_mean_aupr\n",
    "            best_tpr = np.mean(tprs, axis=0)\n",
    "            best_fpr = mean_fpr\n",
    "            best_precision, best_recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "            best_fpr, best_tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        print('Result: ROC: ', top_auc, ' Aupr: ', best_aupr, ' for depth= ', best_depth, ' estimators = ', best_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ROC:  0.9244252271139064  Aupr:  0.86429099336812  for depth=  12  estimators =  40\n",
      "Result: ROC:  0.9244252271139064  Aupr:  0.86429099336812  for depth=  12  estimators =  40\n",
      "Result: ROC:  0.9244252271139064  Aupr:  0.86429099336812  for depth=  12  estimators =  40\n",
      "Result: ROC:  0.9946135569531795  Aupr:  0.9875099306141809  for depth=  12  estimators =  20\n",
      "Result: ROC:  0.9946135569531795  Aupr:  0.9875099306141809  for depth=  12  estimators =  20\n",
      "Result: ROC:  0.9946135569531795  Aupr:  0.9875099306141809  for depth=  12  estimators =  20\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from rusboost import RusBoostClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        tprs = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train = X[train_index]\n",
    "            X_test = X[test_index]\n",
    "            y_train = y[train_index]\n",
    "            y_test = y[test_index]\n",
    "            classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "            classifier.fit(X, y)\n",
    "            predictions = classifier.predict_proba_samme(X_test)\n",
    "            auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "            aupr = average_precision_score(y_test, predictions[:, 1])\n",
    "            current_param_auc.append(auc)\n",
    "            current_param_aupr.append(aupr)\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "            tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        if top_auc < current_mean_auc:\n",
    "            top_auc = current_mean_auc\n",
    "            best_depth = depth\n",
    "            best_estimators = estimators\n",
    "            best_auc = top_auc\n",
    "            best_aupr = current_mean_aupr\n",
    "            best_tpr = np.mean(tprs, axis=0)\n",
    "            best_fpr = mean_fpr\n",
    "            best_precision, best_recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "            best_fpr, best_tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        print('Result: ROC: ', top_auc, ' Aupr: ', best_aupr, ' for depth= ', best_depth, ' estimators = ', best_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on uscecchini28.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1009</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312448</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>-0.019761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.873555</td>\n",
       "      <td>0.167620</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>-0.042140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1011</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>-0.211389</td>\n",
       "      <td>-0.117832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157887</td>\n",
       "      <td>0.745139</td>\n",
       "      <td>-0.428957</td>\n",
       "      <td>-0.157888</td>\n",
       "      <td>0.100228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>1017</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>55.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>-0.105780</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.231337</td>\n",
       "      <td>1.015131</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>0.066348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>24.684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793068</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>-0.249704</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>1</td>\n",
       "      <td>1.043582</td>\n",
       "      <td>1.026261</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>-0.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>1028</td>\n",
       "      <td>7385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869182</td>\n",
       "      <td>-0.231536</td>\n",
       "      <td>-1.674893</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.602508</td>\n",
       "      <td>0.598443</td>\n",
       "      <td>-0.942379</td>\n",
       "      <td>-0.700821</td>\n",
       "      <td>0.130349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146040</th>\n",
       "      <td>2014</td>\n",
       "      <td>314866</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>262.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>0.560406</td>\n",
       "      <td>0.127217</td>\n",
       "      <td>-0.050591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>-0.327178</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.261606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146041</th>\n",
       "      <td>2014</td>\n",
       "      <td>315318</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1578.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742781</td>\n",
       "      <td>-0.118178</td>\n",
       "      <td>0.031360</td>\n",
       "      <td>0.095355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581796</td>\n",
       "      <td>0.743084</td>\n",
       "      <td>-0.077826</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.296702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146042</th>\n",
       "      <td>2014</td>\n",
       "      <td>316056</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>973.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751129</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>-0.037925</td>\n",
       "      <td>0.072050</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>1.063878</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.153133</td>\n",
       "      <td>0.065569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146043</th>\n",
       "      <td>2014</td>\n",
       "      <td>317260</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>51.743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.109467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146044</th>\n",
       "      <td>2014</td>\n",
       "      <td>317264</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>233.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>1.684618</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>1</td>\n",
       "      <td>1.154308</td>\n",
       "      <td>0.745399</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>-0.240183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146045 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "0        1990    1009  3460.0       0               0       0     NaN   \n",
       "1        1990    1011  4841.0       0               0       0     NaN   \n",
       "2        1990    1017  3812.0       0               0       0     NaN   \n",
       "3        1990    1021  3861.0       0               0       0     NaN   \n",
       "4        1990    1028  7385.0       0               0       0     NaN   \n",
       "...       ...     ...     ...     ...             ...     ...     ...   \n",
       "146040   2014  314866  8200.0       0               0       0     NaN   \n",
       "146041   2014  315318  2890.0       0               0       0     NaN   \n",
       "146042   2014  316056  3420.0       0               0       0     NaN   \n",
       "146043   2014  317260  4412.0       0               0       0     NaN   \n",
       "146044   2014  317264  4412.0       0               0       0     NaN   \n",
       "\n",
       "        new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "0              NaN         0    10.047  ...     0.312448  0.095082  0.082631   \n",
       "1              NaN         0     1.247  ...     0.315904  0.188832 -0.211389   \n",
       "2              NaN         0    55.040  ...     0.605342  0.097551 -0.105780   \n",
       "3              NaN         0    24.684  ...     0.793068 -0.005725 -0.249704   \n",
       "4              NaN         0    17.325  ...     0.869182 -0.231536 -1.674893   \n",
       "...            ...       ...       ...  ...          ...       ...       ...   \n",
       "146040         NaN         0   262.600  ...     0.751944  0.560406  0.127217   \n",
       "146041         NaN         0  1578.400  ...     0.742781 -0.118178  0.031360   \n",
       "146042         NaN         0   973.800  ...     0.751129  0.004207 -0.037925   \n",
       "146043         NaN         0    51.743  ...     0.018001       NaN       NaN   \n",
       "146044         NaN         0   233.211  ...     0.068841  1.684618 -0.094348   \n",
       "\n",
       "          ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
       "0      -0.019761      1  0.413170  0.873555  0.167620  0.161961 -0.042140  \n",
       "1      -0.117832      1  0.157887  0.745139 -0.428957 -0.157888  0.100228  \n",
       "2       0.091206      1  2.231337  1.015131  0.394768  0.063681  0.066348  \n",
       "3       0.017545      1  1.043582  1.026261  0.094822  0.088347 -0.017358  \n",
       "4      -0.466667      0 -1.602508  0.598443 -0.942379 -0.700821  0.130349  \n",
       "...          ...    ...       ...       ...       ...       ...       ...  \n",
       "146040 -0.050591      1  0.103693  0.829680 -0.327178 -0.008179 -0.261606  \n",
       "146041  0.095355      1  0.581796  0.743084 -0.077826  0.000461 -0.296702  \n",
       "146042  0.072050      1 -0.000903  1.063878 -0.002877  0.153133  0.065569  \n",
       "146043       NaN      1  1.109467       NaN  0.000000  0.028804       NaN  \n",
       "146044  0.020573      1  1.154308  0.745399  0.025562  0.026433 -0.240183  \n",
       "\n",
       "[146045 rows x 51 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"uscecchini28.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1009</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312448</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>-0.019761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.873555</td>\n",
       "      <td>0.167620</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>-0.042140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1011</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>-0.211389</td>\n",
       "      <td>-0.117832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157887</td>\n",
       "      <td>0.745139</td>\n",
       "      <td>-0.428957</td>\n",
       "      <td>-0.157888</td>\n",
       "      <td>0.100228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>1017</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>-0.105780</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.231337</td>\n",
       "      <td>1.015131</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>0.066348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793068</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>-0.249704</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>1</td>\n",
       "      <td>1.043582</td>\n",
       "      <td>1.026261</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>-0.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>1028</td>\n",
       "      <td>7385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869182</td>\n",
       "      <td>-0.231536</td>\n",
       "      <td>-1.674893</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.602508</td>\n",
       "      <td>0.598443</td>\n",
       "      <td>-0.942379</td>\n",
       "      <td>-0.700821</td>\n",
       "      <td>0.130349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146040</th>\n",
       "      <td>2014</td>\n",
       "      <td>314866</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>262.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>0.560406</td>\n",
       "      <td>0.127217</td>\n",
       "      <td>-0.050591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>-0.327178</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.261606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146041</th>\n",
       "      <td>2014</td>\n",
       "      <td>315318</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1578.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742781</td>\n",
       "      <td>-0.118178</td>\n",
       "      <td>0.031360</td>\n",
       "      <td>0.095355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581796</td>\n",
       "      <td>0.743084</td>\n",
       "      <td>-0.077826</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.296702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146042</th>\n",
       "      <td>2014</td>\n",
       "      <td>316056</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>973.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751129</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>-0.037925</td>\n",
       "      <td>0.072050</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>1.063878</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.153133</td>\n",
       "      <td>0.065569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146043</th>\n",
       "      <td>2014</td>\n",
       "      <td>317260</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.109467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146044</th>\n",
       "      <td>2014</td>\n",
       "      <td>317264</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>233.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>1.684618</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>1</td>\n",
       "      <td>1.154308</td>\n",
       "      <td>0.745399</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>-0.240183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146045 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "0        1990    1009  3460.0       0               0       0     0.0   \n",
       "1        1990    1011  4841.0       0               0       0     0.0   \n",
       "2        1990    1017  3812.0       0               0       0     0.0   \n",
       "3        1990    1021  3861.0       0               0       0     0.0   \n",
       "4        1990    1028  7385.0       0               0       0     0.0   \n",
       "...       ...     ...     ...     ...             ...     ...     ...   \n",
       "146040   2014  314866  8200.0       0               0       0     0.0   \n",
       "146041   2014  315318  2890.0       0               0       0     0.0   \n",
       "146042   2014  316056  3420.0       0               0       0     0.0   \n",
       "146043   2014  317260  4412.0       0               0       0     0.0   \n",
       "146044   2014  317264  4412.0       0               0       0     0.0   \n",
       "\n",
       "        new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "0              0.0         0    10.047  ...     0.312448  0.095082  0.082631   \n",
       "1              0.0         0     1.247  ...     0.315904  0.188832 -0.211389   \n",
       "2              0.0         0    55.040  ...     0.605342  0.097551 -0.105780   \n",
       "3              0.0         0    24.684  ...     0.793068 -0.005725 -0.249704   \n",
       "4              0.0         0    17.325  ...     0.869182 -0.231536 -1.674893   \n",
       "...            ...       ...       ...  ...          ...       ...       ...   \n",
       "146040         0.0         0   262.600  ...     0.751944  0.560406  0.127217   \n",
       "146041         0.0         0  1578.400  ...     0.742781 -0.118178  0.031360   \n",
       "146042         0.0         0   973.800  ...     0.751129  0.004207 -0.037925   \n",
       "146043         0.0         0    51.743  ...     0.018001  0.000000  0.000000   \n",
       "146044         0.0         0   233.211  ...     0.068841  1.684618 -0.094348   \n",
       "\n",
       "          ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
       "0      -0.019761      1  0.413170  0.873555  0.167620  0.161961 -0.042140  \n",
       "1      -0.117832      1  0.157887  0.745139 -0.428957 -0.157888  0.100228  \n",
       "2       0.091206      1  2.231337  1.015131  0.394768  0.063681  0.066348  \n",
       "3       0.017545      1  1.043582  1.026261  0.094822  0.088347 -0.017358  \n",
       "4      -0.466667      0 -1.602508  0.598443 -0.942379 -0.700821  0.130349  \n",
       "...          ...    ...       ...       ...       ...       ...       ...  \n",
       "146040 -0.050591      1  0.103693  0.829680 -0.327178 -0.008179 -0.261606  \n",
       "146041  0.095355      1  0.581796  0.743084 -0.077826  0.000461 -0.296702  \n",
       "146042  0.072050      1 -0.000903  1.063878 -0.002877  0.153133  0.065569  \n",
       "146043  0.000000      1  1.109467  0.000000  0.000000  0.028804  0.000000  \n",
       "146044  0.020573      1  1.154308  0.745399  0.025562  0.026433 -0.240183  \n",
       "\n",
       "[146045 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[(df['fyear'] >= 1991) & (df['fyear'] <= 2001)]\n",
    "test_df = df[df['fyear'] == 2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>1991</td>\n",
       "      <td>1004</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>289.537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836553</td>\n",
       "      <td>-0.095484</td>\n",
       "      <td>0.155827</td>\n",
       "      <td>-0.012672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961101</td>\n",
       "      <td>0.968053</td>\n",
       "      <td>0.259703</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>-0.020650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>1991</td>\n",
       "      <td>1009</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363340</td>\n",
       "      <td>-0.111586</td>\n",
       "      <td>-0.187708</td>\n",
       "      <td>-0.041154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258828</td>\n",
       "      <td>0.859404</td>\n",
       "      <td>0.160184</td>\n",
       "      <td>0.105796</td>\n",
       "      <td>-0.023684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>1991</td>\n",
       "      <td>1011</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350917</td>\n",
       "      <td>0.122455</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>0.067808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151430</td>\n",
       "      <td>0.739250</td>\n",
       "      <td>-0.548968</td>\n",
       "      <td>-0.087615</td>\n",
       "      <td>0.139118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>1991</td>\n",
       "      <td>1013</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>119.530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644304</td>\n",
       "      <td>0.148275</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>-0.038006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483833</td>\n",
       "      <td>1.044093</td>\n",
       "      <td>0.541099</td>\n",
       "      <td>0.154582</td>\n",
       "      <td>-0.097427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>1991</td>\n",
       "      <td>1014</td>\n",
       "      <td>6512.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>-0.436089</td>\n",
       "      <td>0.115207</td>\n",
       "      <td>0</td>\n",
       "      <td>1.017569</td>\n",
       "      <td>0.635725</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>0.257898</td>\n",
       "      <td>-0.198310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71743</th>\n",
       "      <td>2001</td>\n",
       "      <td>233149</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841115</td>\n",
       "      <td>0.665356</td>\n",
       "      <td>-0.233796</td>\n",
       "      <td>-0.278447</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719467</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>-0.258992</td>\n",
       "      <td>-0.218409</td>\n",
       "      <td>-0.393693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71744</th>\n",
       "      <td>2001</td>\n",
       "      <td>233397</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>371.861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225108</td>\n",
       "      <td>3.768149</td>\n",
       "      <td>-1.085016</td>\n",
       "      <td>-0.091807</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.075099</td>\n",
       "      <td>0.579202</td>\n",
       "      <td>-0.381579</td>\n",
       "      <td>-0.041988</td>\n",
       "      <td>-0.233517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71745</th>\n",
       "      <td>2001</td>\n",
       "      <td>241216</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4320.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753478</td>\n",
       "      <td>0.537465</td>\n",
       "      <td>0.203494</td>\n",
       "      <td>-0.058259</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760299</td>\n",
       "      <td>0.536431</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>0.032870</td>\n",
       "      <td>-0.064820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71746</th>\n",
       "      <td>2001</td>\n",
       "      <td>244818</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080238</td>\n",
       "      <td>-6.484197</td>\n",
       "      <td>-1.162185</td>\n",
       "      <td>-0.432618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>1.223529</td>\n",
       "      <td>-2.199320</td>\n",
       "      <td>-0.751347</td>\n",
       "      <td>0.269884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71747</th>\n",
       "      <td>2001</td>\n",
       "      <td>277918</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663825</td>\n",
       "      <td>0.335970</td>\n",
       "      <td>-0.215208</td>\n",
       "      <td>-0.791740</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.099900</td>\n",
       "      <td>0.919303</td>\n",
       "      <td>-20.804839</td>\n",
       "      <td>-0.763825</td>\n",
       "      <td>-0.892924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67166 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "4582    1991    1004  5080.0       0               0       0     0.0   \n",
       "4583    1991    1009  3460.0       0               0       0     0.0   \n",
       "4584    1991    1011  4841.0       0               0       0     0.0   \n",
       "4585    1991    1013  3661.0       0               0       0     0.0   \n",
       "4586    1991    1014  6512.0       1               0       0     0.0   \n",
       "...      ...     ...     ...     ...             ...     ...     ...   \n",
       "71743   2001  233149  4899.0       0               0       0     0.0   \n",
       "71744   2001  233397  4813.0       0               0       0     0.0   \n",
       "71745   2001  241216  2870.0       0               0       0     0.0   \n",
       "71746   2001  244818  3760.0       0               0       0     0.0   \n",
       "71747   2001  277918  3714.0       0               0       0     0.0   \n",
       "\n",
       "       new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "4582          0.0         0   289.537  ...     0.836553 -0.095484  0.155827   \n",
       "4583          0.0         0    12.911  ...     0.363340 -0.111586 -0.187708   \n",
       "4584          0.0         0     3.163  ...     0.350917  0.122455 -0.194342   \n",
       "4585          0.0         0   119.530  ...     0.644304  0.148275  0.034543   \n",
       "4586          0.0         0     6.826  ...     0.245489  0.058214 -0.436089   \n",
       "...           ...       ...       ...  ...          ...       ...       ...   \n",
       "71743         0.0         0    71.622  ...     0.841115  0.665356 -0.233796   \n",
       "71744         0.0         0   371.861  ...     0.225108  3.768149 -1.085016   \n",
       "71745         0.0         0  4320.000  ...     0.753478  0.537465  0.203494   \n",
       "71746         0.0         0     3.413  ...     0.080238 -6.484197 -1.162185   \n",
       "71747         0.0         0     3.454  ...     0.663825  0.335970 -0.215208   \n",
       "\n",
       "         ch_roa  issue        bm       dpi       reoa      EBIT    ch_fcf  \n",
       "4582  -0.012672      1  0.961101  0.968053   0.259703  0.055586 -0.020650  \n",
       "4583  -0.041154      1  0.258828  0.859404   0.160184  0.105796 -0.023684  \n",
       "4584   0.067808      1  0.151430  0.739250  -0.548968 -0.087615  0.139118  \n",
       "4585  -0.038006      1  0.483833  1.044093   0.541099  0.154582 -0.097427  \n",
       "4586   0.115207      0  1.017569  0.635725   0.034610  0.257898 -0.198310  \n",
       "...         ...    ...       ...       ...        ...       ...       ...  \n",
       "71743 -0.278447      1  0.719467  0.807300  -0.258992 -0.218409 -0.393693  \n",
       "71744 -0.091807      1 -0.075099  0.579202  -0.381579 -0.041988 -0.233517  \n",
       "71745 -0.058259      1  0.760299  0.536431  -0.016995  0.032870 -0.064820  \n",
       "71746 -0.432618      1  0.010383  1.223529  -2.199320 -0.751347  0.269884  \n",
       "71747 -0.791740      1 -0.099900  0.919303 -20.804839 -0.763825 -0.892924  \n",
       "\n",
       "[67166 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77815</th>\n",
       "      <td>2003</td>\n",
       "      <td>1004</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>432.204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707952</td>\n",
       "      <td>-0.006354</td>\n",
       "      <td>-0.219484</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976617</td>\n",
       "      <td>1.012580</td>\n",
       "      <td>0.185938</td>\n",
       "      <td>0.028939</td>\n",
       "      <td>0.030194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77816</th>\n",
       "      <td>2003</td>\n",
       "      <td>1013</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1006.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275966</td>\n",
       "      <td>-0.349137</td>\n",
       "      <td>0.216712</td>\n",
       "      <td>0.565607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302803</td>\n",
       "      <td>1.427923</td>\n",
       "      <td>-0.594649</td>\n",
       "      <td>-0.060529</td>\n",
       "      <td>1.291139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77817</th>\n",
       "      <td>2003</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816347</td>\n",
       "      <td>-0.100448</td>\n",
       "      <td>0.163097</td>\n",
       "      <td>-0.228271</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837526</td>\n",
       "      <td>1.441992</td>\n",
       "      <td>-1.707148</td>\n",
       "      <td>-0.214593</td>\n",
       "      <td>0.193321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77818</th>\n",
       "      <td>2003</td>\n",
       "      <td>1034</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>692.991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768092</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>-0.217351</td>\n",
       "      <td>0.048507</td>\n",
       "      <td>1</td>\n",
       "      <td>1.082328</td>\n",
       "      <td>0.904510</td>\n",
       "      <td>0.031126</td>\n",
       "      <td>0.033236</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77819</th>\n",
       "      <td>2003</td>\n",
       "      <td>1038</td>\n",
       "      <td>7830.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>435.736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262861</td>\n",
       "      <td>-0.017864</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495547</td>\n",
       "      <td>0.935015</td>\n",
       "      <td>-0.141191</td>\n",
       "      <td>0.051776</td>\n",
       "      <td>0.078478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83791</th>\n",
       "      <td>2003</td>\n",
       "      <td>252614</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472912</td>\n",
       "      <td>-0.036853</td>\n",
       "      <td>-0.116684</td>\n",
       "      <td>0.102453</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302557</td>\n",
       "      <td>0.626105</td>\n",
       "      <td>-1.264040</td>\n",
       "      <td>-0.067801</td>\n",
       "      <td>0.071843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83792</th>\n",
       "      <td>2003</td>\n",
       "      <td>254096</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.791983</td>\n",
       "      <td>-0.326000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83793</th>\n",
       "      <td>2003</td>\n",
       "      <td>254338</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3081.421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121258</td>\n",
       "      <td>0.492895</td>\n",
       "      <td>-0.069278</td>\n",
       "      <td>0.011349</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513978</td>\n",
       "      <td>0.969363</td>\n",
       "      <td>0.171123</td>\n",
       "      <td>0.109648</td>\n",
       "      <td>-0.017323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83794</th>\n",
       "      <td>2003</td>\n",
       "      <td>264387</td>\n",
       "      <td>3841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.238429</td>\n",
       "      <td>-0.608114</td>\n",
       "      <td>0.032144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235486</td>\n",
       "      <td>1.118996</td>\n",
       "      <td>-0.168644</td>\n",
       "      <td>0.103346</td>\n",
       "      <td>-0.861634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83795</th>\n",
       "      <td>2003</td>\n",
       "      <td>277918</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792402</td>\n",
       "      <td>0.080831</td>\n",
       "      <td>3.263695</td>\n",
       "      <td>0.106817</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100536</td>\n",
       "      <td>0.336116</td>\n",
       "      <td>-19.933676</td>\n",
       "      <td>-0.606160</td>\n",
       "      <td>0.039661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5981 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "77815   2003    1004  5080.0       0               0       0     0.0   \n",
       "77816   2003    1013  3661.0       0               0       0     0.0   \n",
       "77817   2003    1021  3861.0       0               0       0     0.0   \n",
       "77818   2003    1034  2834.0       0               0       0     0.0   \n",
       "77819   2003    1038  7830.0       0               0       0     0.0   \n",
       "...      ...     ...     ...     ...             ...     ...     ...   \n",
       "83791   2003  252614  3674.0       0               0       0     0.0   \n",
       "83792   2003  254096  2836.0       0               0       0     0.0   \n",
       "83793   2003  254338  4813.0       0               0       0     0.0   \n",
       "83794   2003  264387  3841.0       0               0       0     0.0   \n",
       "83795   2003  277918  3714.0       0               0       0     0.0   \n",
       "\n",
       "       new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "77815         0.0         0   432.204  ...     0.707952 -0.006354 -0.219484   \n",
       "77816         0.0         0  1006.000  ...     0.275966 -0.349137  0.216712   \n",
       "77817         0.0         0     5.489  ...     0.816347 -0.100448  0.163097   \n",
       "77818         0.0         0   692.991  ...     0.768092  0.013905 -0.217351   \n",
       "77819         0.0         0   435.736  ...     0.262861 -0.017864 -0.019820   \n",
       "...           ...       ...       ...  ...          ...       ...       ...   \n",
       "83791         0.0         0    18.884  ...     0.472912 -0.036853 -0.116684   \n",
       "83792         0.0         0    16.916  ...     0.355976  0.000000  0.000000   \n",
       "83793         0.0         0  3081.421  ...     0.121258  0.492895 -0.069278   \n",
       "83794         0.0         0    40.375  ...     0.800346 -0.238429 -0.608114   \n",
       "83795         0.0         0     3.025  ...     0.792402  0.080831  3.263695   \n",
       "\n",
       "         ch_roa  issue        bm       dpi       reoa      EBIT    ch_fcf  \n",
       "77815  0.022789      1  0.976617  1.012580   0.185938  0.028939  0.030194  \n",
       "77816  0.565607      1  0.302803  1.427923  -0.594649 -0.060529  1.291139  \n",
       "77817 -0.228271      1  0.837526  1.441992  -1.707148 -0.214593  0.193321  \n",
       "77818  0.048507      1  1.082328  0.904510   0.031126  0.033236  0.006734  \n",
       "77819  0.007507      1  0.495547  0.935015  -0.141191  0.051776  0.078478  \n",
       "...         ...    ...       ...       ...        ...       ...       ...  \n",
       "83791  0.102453      1  0.302557  0.626105  -1.264040 -0.067801  0.071843  \n",
       "83792  0.000000      1  0.344360  0.000000  -1.791983 -0.326000  0.000000  \n",
       "83793  0.011349      1  0.513978  0.969363   0.171123  0.109648 -0.017323  \n",
       "83794  0.032144      0  0.235486  1.118996  -0.168644  0.103346 -0.861634  \n",
       "83795  0.106817      1 -0.100536  0.336116 -19.933676 -0.606160  0.039661  \n",
       "\n",
       "[5981 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67166, 28)\n",
      "(67166,)\n",
      "(5981, 28)\n",
      "(5981,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 9:37]\n",
    "x_test = test[:, 9:37]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost: 1991-2001, 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.2319453432958757  Aupr:  0.006199610398338218  Ndcg:  0.0  Sensitivity:  0.3317929358673956  for depth=  2  estimators =  20\n",
      "AUC:  0.723257535643545  Aupr:  0.020360564728371763  Ndcg:  0.026232950058236792  Sensitivity:  0.6422019128225391  for depth=  2  estimators =  30\n",
      "AUC:  0.6434995881626169  Aupr:  0.016269387213738135  Ndcg:  0.046738891803005396  Sensitivity:  0.7067429748589169  for depth=  2  estimators =  40\n",
      "AUC:  0.7209581102547508  Aupr:  0.021531954145510346  Ndcg:  0.014231278356345666  Sensitivity:  0.7036046079524341  for depth=  12  estimators =  20\n",
      "AUC:  0.731777421505756  Aupr:  0.02302353632167718  Ndcg:  0.062976377433132  Sensitivity:  0.6953125434977478  for depth=  12  estimators =  30\n",
      "AUC:  0.7398021219430879  Aupr:  0.022134459548049778  Ndcg:  0.07605683298404324  Sensitivity:  0.7374539331319562  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from rusboost import RusBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cusboost: 1991-2001, 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7116415151693436  Aupr:  0.04025993622421441  Ndcg:  0.06794181380847784  Sensitivity:  0.1739573638257324  for depth=  2  estimators =  20\n",
      "AUC:  0.6694943715557646  Aupr:  0.05133355942698664  Ndcg:  0.07004127987062791  Sensitivity:  0.11706595681750961  for depth=  2  estimators =  30\n",
      "AUC:  0.7339456962993469  Aupr:  0.03498305959216607  Ndcg:  0.06367641987523748  Sensitivity:  0.3076535750251762  for depth=  2  estimators =  40\n",
      "AUC:  0.7458154380184738  Aupr:  0.023314475044509196  Ndcg:  0.08420560541377735  Sensitivity:  0.7231493503066385  for depth=  12  estimators =  20\n",
      "AUC:  0.7593521405738267  Aupr:  0.028087748854624384  Ndcg:  0.14567970853654694  Sensitivity:  0.7121772907739297  for depth=  12  estimators =  30\n",
      "AUC:  0.7642157439548156  Aupr:  0.02474833209329573  Ndcg:  0.05937817684465589  Sensitivity:  0.7406307743331386  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost: 1991-2002, 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[(df['fyear'] >= 1991) & (df['fyear'] <= 2002)]\n",
    "test_df = df[df['fyear'] == 2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>1991</td>\n",
       "      <td>1004</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>289.537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836553</td>\n",
       "      <td>-0.095484</td>\n",
       "      <td>0.155827</td>\n",
       "      <td>-0.012672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961101</td>\n",
       "      <td>0.968053</td>\n",
       "      <td>0.259703</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>-0.020650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>1991</td>\n",
       "      <td>1009</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363340</td>\n",
       "      <td>-0.111586</td>\n",
       "      <td>-0.187708</td>\n",
       "      <td>-0.041154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258828</td>\n",
       "      <td>0.859404</td>\n",
       "      <td>0.160184</td>\n",
       "      <td>0.105796</td>\n",
       "      <td>-0.023684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>1991</td>\n",
       "      <td>1011</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350917</td>\n",
       "      <td>0.122455</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>0.067808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151430</td>\n",
       "      <td>0.739250</td>\n",
       "      <td>-0.548968</td>\n",
       "      <td>-0.087615</td>\n",
       "      <td>0.139118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>1991</td>\n",
       "      <td>1013</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>119.530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644304</td>\n",
       "      <td>0.148275</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>-0.038006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483833</td>\n",
       "      <td>1.044093</td>\n",
       "      <td>0.541099</td>\n",
       "      <td>0.154582</td>\n",
       "      <td>-0.097427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>1991</td>\n",
       "      <td>1014</td>\n",
       "      <td>6512.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>-0.436089</td>\n",
       "      <td>0.115207</td>\n",
       "      <td>0</td>\n",
       "      <td>1.017569</td>\n",
       "      <td>0.635725</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>0.257898</td>\n",
       "      <td>-0.198310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77810</th>\n",
       "      <td>2002</td>\n",
       "      <td>244818</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067889</td>\n",
       "      <td>-0.354610</td>\n",
       "      <td>2.120761</td>\n",
       "      <td>-0.701408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>0.536265</td>\n",
       "      <td>-2.578969</td>\n",
       "      <td>-1.083602</td>\n",
       "      <td>-0.413143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77811</th>\n",
       "      <td>2002</td>\n",
       "      <td>249158</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.140719</td>\n",
       "      <td>-0.016401</td>\n",
       "      <td>0.024218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543739</td>\n",
       "      <td>1.178880</td>\n",
       "      <td>0.028183</td>\n",
       "      <td>0.064690</td>\n",
       "      <td>0.009596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77812</th>\n",
       "      <td>2002</td>\n",
       "      <td>252614</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.276576</td>\n",
       "      <td>1.765173</td>\n",
       "      <td>-1.500604</td>\n",
       "      <td>-0.235980</td>\n",
       "      <td>0.180804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77813</th>\n",
       "      <td>2002</td>\n",
       "      <td>254338</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3200.725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112064</td>\n",
       "      <td>0.083356</td>\n",
       "      <td>0.121587</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.155478</td>\n",
       "      <td>0.977792</td>\n",
       "      <td>0.218314</td>\n",
       "      <td>0.104528</td>\n",
       "      <td>-0.044975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77814</th>\n",
       "      <td>2002</td>\n",
       "      <td>277918</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569569</td>\n",
       "      <td>0.248661</td>\n",
       "      <td>-0.730804</td>\n",
       "      <td>0.241068</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144448</td>\n",
       "      <td>2.980843</td>\n",
       "      <td>-15.085315</td>\n",
       "      <td>-0.546112</td>\n",
       "      <td>0.062287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73233 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "4582    1991    1004  5080.0       0               0       0     0.0   \n",
       "4583    1991    1009  3460.0       0               0       0     0.0   \n",
       "4584    1991    1011  4841.0       0               0       0     0.0   \n",
       "4585    1991    1013  3661.0       0               0       0     0.0   \n",
       "4586    1991    1014  6512.0       1               0       0     0.0   \n",
       "...      ...     ...     ...     ...             ...     ...     ...   \n",
       "77810   2002  244818  3760.0       0               0       0     0.0   \n",
       "77811   2002  249158  4412.0       0               0       0     0.0   \n",
       "77812   2002  252614  3674.0       0               0       0     0.0   \n",
       "77813   2002  254338  4813.0       0               0       0     0.0   \n",
       "77814   2002  277918  3714.0       0               0       0     0.0   \n",
       "\n",
       "       new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "4582          0.0         0   289.537  ...     0.836553 -0.095484  0.155827   \n",
       "4583          0.0         0    12.911  ...     0.363340 -0.111586 -0.187708   \n",
       "4584          0.0         0     3.163  ...     0.350917  0.122455 -0.194342   \n",
       "4585          0.0         0   119.530  ...     0.644304  0.148275  0.034543   \n",
       "4586          0.0         0     6.826  ...     0.245489  0.058214 -0.436089   \n",
       "...           ...       ...       ...  ...          ...       ...       ...   \n",
       "77810         0.0         0     4.872  ...     0.067889 -0.354610  2.120761   \n",
       "77811         0.0         0    71.022  ...     0.013341  0.140719 -0.016401   \n",
       "77812         0.0         0    10.821  ...     0.568342  0.000000  0.000000   \n",
       "77813         0.0         0  3200.725  ...     0.112064  0.083356  0.121587   \n",
       "77814         0.0         0     4.915  ...     0.569569  0.248661 -0.730804   \n",
       "\n",
       "         ch_roa  issue        bm       dpi       reoa      EBIT    ch_fcf  \n",
       "4582  -0.012672      1  0.961101  0.968053   0.259703  0.055586 -0.020650  \n",
       "4583  -0.041154      1  0.258828  0.859404   0.160184  0.105796 -0.023684  \n",
       "4584   0.067808      1  0.151430  0.739250  -0.548968 -0.087615  0.139118  \n",
       "4585  -0.038006      1  0.483833  1.044093   0.541099  0.154582 -0.097427  \n",
       "4586   0.115207      0  1.017569  0.635725   0.034610  0.257898 -0.198310  \n",
       "...         ...    ...       ...       ...        ...       ...       ...  \n",
       "77810 -0.701408      1  0.030881  0.536265  -2.578969 -1.083602 -0.413143  \n",
       "77811  0.024218      1  0.543739  1.178880   0.028183  0.064690  0.009596  \n",
       "77812  0.000000      1  1.276576  1.765173  -1.500604 -0.235980  0.180804  \n",
       "77813  0.048667      1  1.155478  0.977792   0.218314  0.104528 -0.044975  \n",
       "77814  0.241068      1 -0.144448  2.980843 -15.085315 -0.546112  0.062287  \n",
       "\n",
       "[73233 rows x 51 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83796</th>\n",
       "      <td>2004</td>\n",
       "      <td>1004</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>474.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741236</td>\n",
       "      <td>0.182147</td>\n",
       "      <td>0.372365</td>\n",
       "      <td>0.016419</td>\n",
       "      <td>0</td>\n",
       "      <td>0.602174</td>\n",
       "      <td>0.827183</td>\n",
       "      <td>0.194543</td>\n",
       "      <td>0.047713</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83797</th>\n",
       "      <td>2004</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884548</td>\n",
       "      <td>0.072180</td>\n",
       "      <td>0.106097</td>\n",
       "      <td>0.436975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191637</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>-1.436990</td>\n",
       "      <td>0.232826</td>\n",
       "      <td>-0.017577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83798</th>\n",
       "      <td>2004</td>\n",
       "      <td>1045</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4971.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216488</td>\n",
       "      <td>0.026483</td>\n",
       "      <td>-0.126412</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.329242</td>\n",
       "      <td>1.044921</td>\n",
       "      <td>-0.068675</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.037657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83799</th>\n",
       "      <td>2004</td>\n",
       "      <td>1050</td>\n",
       "      <td>3564.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776156</td>\n",
       "      <td>-0.030364</td>\n",
       "      <td>-0.202920</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210874</td>\n",
       "      <td>0.974546</td>\n",
       "      <td>-0.170277</td>\n",
       "      <td>0.031882</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83800</th>\n",
       "      <td>2004</td>\n",
       "      <td>1056</td>\n",
       "      <td>3825.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>327.480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686477</td>\n",
       "      <td>0.298371</td>\n",
       "      <td>0.102035</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402660</td>\n",
       "      <td>0.771520</td>\n",
       "      <td>0.089214</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>-0.250891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89725</th>\n",
       "      <td>2004</td>\n",
       "      <td>269005</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1214.267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595114</td>\n",
       "      <td>0.284639</td>\n",
       "      <td>-0.188115</td>\n",
       "      <td>0.049676</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516199</td>\n",
       "      <td>2.074633</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.095256</td>\n",
       "      <td>-0.020758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89726</th>\n",
       "      <td>2004</td>\n",
       "      <td>270281</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2103.205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685137</td>\n",
       "      <td>1.057751</td>\n",
       "      <td>0.441486</td>\n",
       "      <td>0.426802</td>\n",
       "      <td>0.211946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89727</th>\n",
       "      <td>2004</td>\n",
       "      <td>270287</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.077990</td>\n",
       "      <td>0.085078</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89728</th>\n",
       "      <td>2004</td>\n",
       "      <td>274075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.425624</td>\n",
       "      <td>-0.013145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89729</th>\n",
       "      <td>2004</td>\n",
       "      <td>277918</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666780</td>\n",
       "      <td>-0.406100</td>\n",
       "      <td>-0.066763</td>\n",
       "      <td>-0.054377</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.083773</td>\n",
       "      <td>0.854940</td>\n",
       "      <td>-17.061651</td>\n",
       "      <td>-0.531080</td>\n",
       "      <td>-0.033649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5934 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "83796   2004    1004  5080.0       0               0       0     0.0   \n",
       "83797   2004    1021  3861.0       0               0       0     0.0   \n",
       "83798   2004    1045  4512.0       0               0       0     0.0   \n",
       "83799   2004    1050  3564.0       0               0       0     0.0   \n",
       "83800   2004    1056  3825.0       0               0       0     0.0   \n",
       "...      ...     ...     ...     ...             ...     ...     ...   \n",
       "89725   2004  269005  4911.0       0               0       0     0.0   \n",
       "89726   2004  270281  3312.0       0               0       0     0.0   \n",
       "89727   2004  270287  4899.0       0               0       0     0.0   \n",
       "89728   2004  274075     0.0       0               0       0     0.0   \n",
       "89729   2004  277918  3714.0       0               0       0     0.0   \n",
       "\n",
       "       new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "83796         0.0         0   474.542  ...     0.741236  0.182147  0.372365   \n",
       "83797         0.0         0     5.807  ...     0.884548  0.072180  0.106097   \n",
       "83798         0.0         0  4971.000  ...     0.216488  0.026483 -0.126412   \n",
       "83799         0.0         0    21.779  ...     0.776156 -0.030364 -0.202920   \n",
       "83800         0.0         0   327.480  ...     0.686477  0.298371  0.102035   \n",
       "...           ...       ...       ...  ...          ...       ...       ...   \n",
       "89725         0.0         0  1214.267  ...     0.595114  0.284639 -0.188115   \n",
       "89726         0.0         0  2103.205  ...     0.374846  0.000000  0.000000   \n",
       "89727         0.0         0   112.420  ...     0.773637  0.000000  0.000000   \n",
       "89728         0.0         0     0.228  ...     0.145258  0.000000  0.000000   \n",
       "89729         0.0         0     3.437  ...     0.666780 -0.406100 -0.066763   \n",
       "\n",
       "         ch_roa  issue        bm       dpi       reoa      EBIT    ch_fcf  \n",
       "83796  0.016419      0  0.602174  0.827183   0.194543  0.047713  0.002089  \n",
       "83797  0.436975      0  0.191637  1.070634  -1.436990  0.232826 -0.017577  \n",
       "83798  0.015015      1 -0.329242  1.044921  -0.068675  0.003823  0.037657  \n",
       "83799 -0.006752      1  0.210874  0.974546  -0.170277  0.031882  0.017093  \n",
       "83800  0.007839      1  0.402660  0.771520   0.089214  0.047166 -0.250891  \n",
       "...         ...    ...       ...       ...        ...       ...       ...  \n",
       "89725  0.049676      1  0.516199  2.074633   0.001105  0.095256 -0.020758  \n",
       "89726  0.000000      1  0.685137  1.057751   0.441486  0.426802  0.211946  \n",
       "89727  0.000000      1  0.315422  0.000000  -0.077990  0.085078  0.000000  \n",
       "89728  0.000000      1  0.140871  0.000000  -2.425624 -0.013145  0.000000  \n",
       "89729 -0.054377      1 -0.083773  0.854940 -17.061651 -0.531080 -0.033649  \n",
       "\n",
       "[5934 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73233, 28)\n",
      "(73233,)\n",
      "(5934, 28)\n",
      "(5934,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 9:37]\n",
    "x_test = test[:, 9:37]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.733125396117462  Aupr:  0.018907918930654685  Ndcg:  0.04519087485951688  Sensitivity:  0.7326924772907664  for depth=  2  estimators =  20\n",
      "AUC:  0.7314705053871975  Aupr:  0.017245820306988572  Ndcg:  0.012059506902607672  Sensitivity:  0.7553039400697662  for depth=  2  estimators =  30\n",
      "AUC:  0.6675914297786437  Aupr:  0.015006029009994372  Ndcg:  0.01247327799883532  Sensitivity:  0.6205900260142801  for depth=  2  estimators =  40\n",
      "AUC:  0.7910069599305181  Aupr:  0.022608734102569795  Ndcg:  0.07038235133621958  Sensitivity:  0.7327864037594463  for depth=  12  estimators =  20\n",
      "AUC:  0.75870138024929  Aupr:  0.020688430341900845  Ndcg:  0.09568993917075913  Sensitivity:  0.6951167505854363  for depth=  12  estimators =  30\n",
      "AUC:  0.7656393042416845  Aupr:  0.021192038398420692  Ndcg:  0.05913711960254216  Sensitivity:  0.7387813822647252  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from rusboost import RusBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cusboost: 1991-2002, 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7255786249149081  Aupr:  0.03200276993438338  Ndcg:  0.04963706987783095  Sensitivity:  0.1523371647509579  for depth=  2  estimators =  20\n",
      "AUC:  0.718275392596418  Aupr:  0.02315857678792294  Ndcg:  0.03130080872308706  Sensitivity:  0.28897583627139056  for depth=  2  estimators =  30\n",
      "AUC:  0.7220707847233633  Aupr:  0.025127449541379365  Ndcg:  0.03598170796642474  Sensitivity:  0.3371330863493873  for depth=  2  estimators =  40\n",
      "AUC:  0.7058387713903429  Aupr:  0.01830005662710687  Ndcg:  0.06297029110528543  Sensitivity:  0.6885201406452408  for depth=  12  estimators =  20\n",
      "AUC:  0.7008462242670359  Aupr:  0.018486995510476886  Ndcg:  0.060511501440496065  Sensitivity:  0.688321967485449  for depth=  12  estimators =  30\n",
      "AUC:  0.7274770545292363  Aupr:  0.021257380870021207  Ndcg:  0.0780155438458821  Sensitivity:  0.6858440600474478  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost: 1991-2003, 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[(df['fyear'] >= 1991) & (df['fyear'] <= 2003)]\n",
    "test_df = df[df['fyear'] == 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89730</th>\n",
       "      <td>2005</td>\n",
       "      <td>1013</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>853.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565798</td>\n",
       "      <td>0.545828</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380683</td>\n",
       "      <td>0.651258</td>\n",
       "      <td>-0.422476</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>-0.292194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89731</th>\n",
       "      <td>2005</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911689</td>\n",
       "      <td>0.171468</td>\n",
       "      <td>0.056120</td>\n",
       "      <td>0.045031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236020</td>\n",
       "      <td>0.931946</td>\n",
       "      <td>-0.867533</td>\n",
       "      <td>0.166074</td>\n",
       "      <td>-0.200583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89732</th>\n",
       "      <td>2005</td>\n",
       "      <td>1034</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1037.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374649</td>\n",
       "      <td>-0.497353</td>\n",
       "      <td>0.222937</td>\n",
       "      <td>0.219029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595473</td>\n",
       "      <td>0.673763</td>\n",
       "      <td>-0.107975</td>\n",
       "      <td>0.101711</td>\n",
       "      <td>0.564341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89733</th>\n",
       "      <td>2005</td>\n",
       "      <td>1045</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6164.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224614</td>\n",
       "      <td>0.104918</td>\n",
       "      <td>-0.027229</td>\n",
       "      <td>-0.003358</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.363848</td>\n",
       "      <td>1.070900</td>\n",
       "      <td>-0.106866</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.027974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89734</th>\n",
       "      <td>2005</td>\n",
       "      <td>1050</td>\n",
       "      <td>3564.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787739</td>\n",
       "      <td>0.235590</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118256</td>\n",
       "      <td>0.925700</td>\n",
       "      <td>-0.183287</td>\n",
       "      <td>0.061189</td>\n",
       "      <td>0.021542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95588</th>\n",
       "      <td>2005</td>\n",
       "      <td>270281</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1359.483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494245</td>\n",
       "      <td>0.080589</td>\n",
       "      <td>-0.192915</td>\n",
       "      <td>-0.382382</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680608</td>\n",
       "      <td>0.976028</td>\n",
       "      <td>0.488680</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>-0.481795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95589</th>\n",
       "      <td>2005</td>\n",
       "      <td>270287</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.314446</td>\n",
       "      <td>0.882678</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>0.106001</td>\n",
       "      <td>-0.154301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95590</th>\n",
       "      <td>2005</td>\n",
       "      <td>270989</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.066561</td>\n",
       "      <td>0.079794</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95591</th>\n",
       "      <td>2005</td>\n",
       "      <td>272705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371865</td>\n",
       "      <td>1.118226</td>\n",
       "      <td>0.147289</td>\n",
       "      <td>0.089021</td>\n",
       "      <td>-0.226063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95592</th>\n",
       "      <td>2005</td>\n",
       "      <td>274075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114319</td>\n",
       "      <td>3.270108</td>\n",
       "      <td>-0.360957</td>\n",
       "      <td>-0.043492</td>\n",
       "      <td>-0.821665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5863 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "89730   2005    1013  3661.0       0               0       0     0.0   \n",
       "89731   2005    1021  3861.0       0               0       0     0.0   \n",
       "89732   2005    1034  2834.0       0               0       0     0.0   \n",
       "89733   2005    1045  4512.0       0               0       0     0.0   \n",
       "89734   2005    1050  3564.0       0               0       0     0.0   \n",
       "...      ...     ...     ...     ...             ...     ...     ...   \n",
       "95588   2005  270281  3312.0       0               0       0     0.0   \n",
       "95589   2005  270287  4899.0       0               0       0     0.0   \n",
       "95590   2005  270989  8200.0       0               0       0     0.0   \n",
       "95591   2005  272705     0.0       0               0       0     0.0   \n",
       "95592   2005  274075     0.0       0               0       0     0.0   \n",
       "\n",
       "       new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "89730         0.0         0   853.000  ...     0.565798  0.545828  0.067576   \n",
       "89731         0.0         0     7.726  ...     0.911689  0.171468  0.056120   \n",
       "89732         0.0         0  1037.047  ...     0.374649 -0.497353  0.222937   \n",
       "89733         0.0         0  6164.000  ...     0.224614  0.104918 -0.027229   \n",
       "89734         0.0         0    21.795  ...     0.787739  0.235590  0.672269   \n",
       "...           ...       ...       ...  ...          ...       ...       ...   \n",
       "95588         0.0         0  1359.483  ...     0.494245  0.080589 -0.192915   \n",
       "95589         0.0         0   144.780  ...     0.736825  0.000000  0.000000   \n",
       "95590         0.0         0    57.224  ...     0.387777  0.000000  0.000000   \n",
       "95591         0.0         0   127.345  ...     0.920693  0.000000  0.000000   \n",
       "95592         0.0         0    11.052  ...     0.054458  0.000000  0.000000   \n",
       "\n",
       "         ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
       "89730  0.062682      1  0.380683  0.651258 -0.422476  0.084104 -0.292194  \n",
       "89731  0.045031      1  0.236020  0.931946 -0.867533  0.166074 -0.200583  \n",
       "89732  0.219029      1  0.595473  0.673763 -0.107975  0.101711  0.564341  \n",
       "89733 -0.003358      1 -0.363848  1.070900 -0.106866  0.003255  0.027974  \n",
       "89734  0.011864      0  0.118256  0.925700 -0.183287  0.061189  0.021542  \n",
       "...         ...    ...       ...       ...       ...       ...       ...  \n",
       "95588 -0.382382      1  0.680608  0.976028  0.488680  0.160000 -0.481795  \n",
       "95589  0.000000      1  0.314446  0.882678  0.024778  0.106001 -0.154301  \n",
       "95590  0.000000      0  0.030482  0.000000 -0.066561  0.079794  0.000000  \n",
       "95591  0.000000      1  0.371865  1.118226  0.147289  0.089021 -0.226063  \n",
       "95592  0.000000      1  0.114319  3.270108 -0.360957 -0.043492 -0.821665  \n",
       "\n",
       "[5863 rows x 51 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79214, 28)\n",
      "(79214,)\n",
      "(5863, 28)\n",
      "(5863,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 9:37]\n",
    "x_test = test[:, 9:37]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.680884992933807  Aupr:  0.011337288426394724  Ndcg:  0.0  Sensitivity:  0.8231720186944068  for depth=  2  estimators =  20\n",
      "AUC:  0.7182116802261183  Aupr:  0.01441316070763762  Ndcg:  0.0208210657429204  Sensitivity:  0.7522734399498276  for depth=  2  estimators =  30\n",
      "AUC:  0.7284347427523776  Aupr:  0.01426210856656531  Ndcg:  0.01665685259433632  Sensitivity:  0.6547122667291325  for depth=  2  estimators =  40\n",
      "AUC:  0.7349146327489401  Aupr:  0.013885813375909179  Ndcg:  0.01927016395071518  Sensitivity:  0.7390968508615569  for depth=  12  estimators =  20\n",
      "AUC:  0.7508651312020168  Aupr:  0.01580529737374663  Ndcg:  0.03678680610024773  Sensitivity:  0.7442198210758686  for depth=  12  estimators =  30\n",
      "AUC:  0.7341087047859134  Aupr:  0.01481014365825533  Ndcg:  0.026273259756551766  Sensitivity:  0.7305182635303117  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from rusboost import RusBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cusboost: 1991-2003, 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6752530461021351  Aupr:  0.013616795741434087  Ndcg:  0.01651026089576714  Sensitivity:  0.26055101422948834  for depth=  2  estimators =  20\n",
      "AUC:  0.6705759902219166  Aupr:  0.014507328204942584  Ndcg:  0.02407455101092244  Sensitivity:  0.3463040446304045  for depth=  2  estimators =  30\n",
      "AUC:  0.6805278637179634  Aupr:  0.01666164320641024  Ndcg:  0.027761420990560528  Sensitivity:  0.3785318252384121  for depth=  2  estimators =  40\n",
      "AUC:  0.6910278446201443  Aupr:  0.015104726257104616  Ndcg:  0.10181102802209266  Sensitivity:  0.6664352282354888  for depth=  12  estimators =  20\n",
      "AUC:  0.703296283564417  Aupr:  0.015467672173982221  Ndcg:  0.12007372737765629  Sensitivity:  0.6732780996283145  for depth=  12  estimators =  30\n",
      "AUC:  0.7048202895229365  Aupr:  0.015413614089641703  Ndcg:  0.10973237467939957  Sensitivity:  0.6696332869139553  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost: 1991-2004, 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[(df['fyear'] >= 1991) & (df['fyear'] <= 2004)]\n",
    "test_df = df[df['fyear'] == 2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95593</th>\n",
       "      <td>2006</td>\n",
       "      <td>1013</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>942.700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.170354</td>\n",
       "      <td>-0.060640</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520830</td>\n",
       "      <td>0.943020</td>\n",
       "      <td>-0.352116</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>-0.038457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95594</th>\n",
       "      <td>2006</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610139</td>\n",
       "      <td>0.087639</td>\n",
       "      <td>-0.081807</td>\n",
       "      <td>-0.174568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204218</td>\n",
       "      <td>0.859982</td>\n",
       "      <td>-0.416777</td>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.242287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95595</th>\n",
       "      <td>2006</td>\n",
       "      <td>1034</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>353.541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626191</td>\n",
       "      <td>-0.076063</td>\n",
       "      <td>0.089925</td>\n",
       "      <td>-0.009034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.697034</td>\n",
       "      <td>1.532180</td>\n",
       "      <td>-0.096779</td>\n",
       "      <td>0.127191</td>\n",
       "      <td>-0.347585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95596</th>\n",
       "      <td>2006</td>\n",
       "      <td>1045</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6902.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206588</td>\n",
       "      <td>0.097728</td>\n",
       "      <td>0.214712</td>\n",
       "      <td>0.037432</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.090208</td>\n",
       "      <td>0.974812</td>\n",
       "      <td>-0.109281</td>\n",
       "      <td>0.043266</td>\n",
       "      <td>0.006924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95597</th>\n",
       "      <td>2006</td>\n",
       "      <td>1050</td>\n",
       "      <td>3564.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857964</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>-0.539549</td>\n",
       "      <td>0.068405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144855</td>\n",
       "      <td>0.938543</td>\n",
       "      <td>-0.083212</td>\n",
       "      <td>0.108549</td>\n",
       "      <td>-0.089737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101496</th>\n",
       "      <td>2006</td>\n",
       "      <td>277579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>131.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088249</td>\n",
       "      <td>-0.069826</td>\n",
       "      <td>-0.297817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101497</th>\n",
       "      <td>2006</td>\n",
       "      <td>277846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>0.026559</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101498</th>\n",
       "      <td>2006</td>\n",
       "      <td>278234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615253</td>\n",
       "      <td>0.412875</td>\n",
       "      <td>-0.066037</td>\n",
       "      <td>-0.061456</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095816</td>\n",
       "      <td>1.523967</td>\n",
       "      <td>0.457610</td>\n",
       "      <td>0.550619</td>\n",
       "      <td>-0.734577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101499</th>\n",
       "      <td>2006</td>\n",
       "      <td>278400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033473</td>\n",
       "      <td>-0.020385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101500</th>\n",
       "      <td>2006</td>\n",
       "      <td>279398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>234.852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304711</td>\n",
       "      <td>0.151757</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>0.369730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5908 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "95593    2006    1013  3661.0       0               0       0     0.0   \n",
       "95594    2006    1021  3861.0       0               0       0     0.0   \n",
       "95595    2006    1034  2834.0       0               0       0     0.0   \n",
       "95596    2006    1045  4512.0       0               0       0     0.0   \n",
       "95597    2006    1050  3564.0       0               0       0     0.0   \n",
       "...       ...     ...     ...     ...             ...     ...     ...   \n",
       "101496   2006  277579     0.0       0               0       0     0.0   \n",
       "101497   2006  277846     0.0       0               0       0     0.0   \n",
       "101498   2006  278234     0.0       0               0       0     0.0   \n",
       "101499   2006  278400     0.0       0               0       0     0.0   \n",
       "101500   2006  279398     0.0       0               0       0     0.0   \n",
       "\n",
       "        new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "95593          0.0         0   942.700  ...     0.538166  0.170354 -0.060640   \n",
       "95594          0.0         0    13.582  ...     0.610139  0.087639 -0.081807   \n",
       "95595          0.0         0   353.541  ...     0.626191 -0.076063  0.089925   \n",
       "95596          0.0         0  6902.000  ...     0.206588  0.097728  0.214712   \n",
       "95597          0.0         0    42.653  ...     0.857964  0.475099 -0.539549   \n",
       "...            ...       ...       ...  ...          ...       ...       ...   \n",
       "101496         0.0         0   131.250  ...     0.004515  0.000000  0.000000   \n",
       "101497         0.0         0    78.441  ...     0.918373  0.000000  0.000000   \n",
       "101498         0.0         0   115.035  ...     0.615253  0.412875 -0.066037   \n",
       "101499         0.0         0    24.733  ...     0.106035  0.000000  0.000000   \n",
       "101500         0.0         0   234.852  ...     0.044970  0.000000  0.000000   \n",
       "\n",
       "          ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
       "95593  -0.032957      1  0.520830  0.943020 -0.352116  0.027181 -0.038457  \n",
       "95594  -0.174568      1  0.204218  0.859982 -0.416777  0.072240  0.242287  \n",
       "95595  -0.009034      1  0.697034  1.532180 -0.096779  0.127191 -0.347585  \n",
       "95596   0.037432      1 -0.090208  0.974812 -0.109281  0.043266  0.006924  \n",
       "95597   0.068405      1  0.144855  0.938543 -0.083212  0.108549 -0.089737  \n",
       "...          ...    ...       ...       ...       ...       ...       ...  \n",
       "101496  0.000000      1  0.337848  0.000000 -0.088249 -0.069826 -0.297817  \n",
       "101497  0.000000      1  0.728082  0.000000 -0.001117  0.026559  0.000000  \n",
       "101498 -0.061456      1  0.095816  1.523967  0.457610  0.550619 -0.734577  \n",
       "101499  0.000000      1  0.300921  0.000000 -0.033473 -0.020385  0.000000  \n",
       "101500  0.000000      1  0.304711  0.151757  0.007979 -0.012282  0.369730  \n",
       "\n",
       "[5908 rows x 51 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85148, 28)\n",
      "(85148,)\n",
      "(5908, 28)\n",
      "(5908,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 9:37]\n",
    "x_test = test[:, 9:37]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6690135396518375  Aupr:  0.008587977622564011  Ndcg:  0.0  Sensitivity:  0.7038265870382658  for depth=  2  estimators =  20\n",
      "AUC:  0.7264861379754997  Aupr:  0.009979978605723108  Ndcg:  0.0  Sensitivity:  0.7592776042063552  for depth=  2  estimators =  30\n",
      "AUC:  0.6957704706640877  Aupr:  0.00815246947254706  Ndcg:  0.0  Sensitivity:  0.7577527382848603  for depth=  2  estimators =  40\n",
      "AUC:  0.7391025145067699  Aupr:  0.010477940120636846  Ndcg:  0.017352108422616152  Sensitivity:  0.7119140568014052  for depth=  12  estimators =  20\n",
      "AUC:  0.738728562217924  Aupr:  0.010620278805809654  Ndcg:  0.0  Sensitivity:  0.6816998106060607  for depth=  12  estimators =  30\n",
      "AUC:  0.7265402965828498  Aupr:  0.009574296969816756  Ndcg:  0.017894278886829786  Sensitivity:  0.6913928771425437  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from rusboost import RusBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6371192778852354  Aupr:  0.012539062962937745  Ndcg:  0.025075948096980688  Sensitivity:  0.19798778296802014  for depth=  2  estimators =  20\n",
      "AUC:  0.6337949709864603  Aupr:  0.010896741176518404  Ndcg:  0.019825627262858934  Sensitivity:  0.286770140428677  for depth=  2  estimators =  30\n",
      "AUC:  0.6429864603481624  Aupr:  0.009886573482729564  Ndcg:  0.02109868403320897  Sensitivity:  0.3720385674931129  for depth=  2  estimators =  40\n",
      "AUC:  0.7068678272082527  Aupr:  0.010761355707778537  Ndcg:  0.02562425151388268  Sensitivity:  0.6247516414689668  for depth=  12  estimators =  20\n",
      "AUC:  0.7191850419084462  Aupr:  0.009457799954173873  Ndcg:  0.02088838217572278  Sensitivity:  0.6984505690388043  for depth=  12  estimators =  30\n",
      "AUC:  0.7502566086395873  Aupr:  0.012813419157708996  Ndcg:  0.058873391762003735  Sensitivity:  0.6899479542605326  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1009</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312448</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>-0.019761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.873555</td>\n",
       "      <td>0.167620</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>-0.042140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1011</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>-0.211389</td>\n",
       "      <td>-0.117832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157887</td>\n",
       "      <td>0.745139</td>\n",
       "      <td>-0.428957</td>\n",
       "      <td>-0.157888</td>\n",
       "      <td>0.100228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>1017</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>55.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>-0.105780</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.231337</td>\n",
       "      <td>1.015131</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>0.066348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>24.684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793068</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>-0.249704</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>1</td>\n",
       "      <td>1.043582</td>\n",
       "      <td>1.026261</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>-0.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>1028</td>\n",
       "      <td>7385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869182</td>\n",
       "      <td>-0.231536</td>\n",
       "      <td>-1.674893</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.602508</td>\n",
       "      <td>0.598443</td>\n",
       "      <td>-0.942379</td>\n",
       "      <td>-0.700821</td>\n",
       "      <td>0.130349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146040</th>\n",
       "      <td>2014</td>\n",
       "      <td>314866</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>262.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>0.560406</td>\n",
       "      <td>0.127217</td>\n",
       "      <td>-0.050591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>-0.327178</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.261606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146041</th>\n",
       "      <td>2014</td>\n",
       "      <td>315318</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1578.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742781</td>\n",
       "      <td>-0.118178</td>\n",
       "      <td>0.031360</td>\n",
       "      <td>0.095355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581796</td>\n",
       "      <td>0.743084</td>\n",
       "      <td>-0.077826</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.296702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146042</th>\n",
       "      <td>2014</td>\n",
       "      <td>316056</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>973.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751129</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>-0.037925</td>\n",
       "      <td>0.072050</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>1.063878</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.153133</td>\n",
       "      <td>0.065569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146043</th>\n",
       "      <td>2014</td>\n",
       "      <td>317260</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>51.743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.109467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146044</th>\n",
       "      <td>2014</td>\n",
       "      <td>317264</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>233.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>1.684618</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>1</td>\n",
       "      <td>1.154308</td>\n",
       "      <td>0.745399</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>-0.240183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146045 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "0        1990    1009  3460.0       0               0       0     NaN   \n",
       "1        1990    1011  4841.0       0               0       0     NaN   \n",
       "2        1990    1017  3812.0       0               0       0     NaN   \n",
       "3        1990    1021  3861.0       0               0       0     NaN   \n",
       "4        1990    1028  7385.0       0               0       0     NaN   \n",
       "...       ...     ...     ...     ...             ...     ...     ...   \n",
       "146040   2014  314866  8200.0       0               0       0     NaN   \n",
       "146041   2014  315318  2890.0       0               0       0     NaN   \n",
       "146042   2014  316056  3420.0       0               0       0     NaN   \n",
       "146043   2014  317260  4412.0       0               0       0     NaN   \n",
       "146044   2014  317264  4412.0       0               0       0     NaN   \n",
       "\n",
       "        new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "0              NaN         0    10.047  ...     0.312448  0.095082  0.082631   \n",
       "1              NaN         0     1.247  ...     0.315904  0.188832 -0.211389   \n",
       "2              NaN         0    55.040  ...     0.605342  0.097551 -0.105780   \n",
       "3              NaN         0    24.684  ...     0.793068 -0.005725 -0.249704   \n",
       "4              NaN         0    17.325  ...     0.869182 -0.231536 -1.674893   \n",
       "...            ...       ...       ...  ...          ...       ...       ...   \n",
       "146040         NaN         0   262.600  ...     0.751944  0.560406  0.127217   \n",
       "146041         NaN         0  1578.400  ...     0.742781 -0.118178  0.031360   \n",
       "146042         NaN         0   973.800  ...     0.751129  0.004207 -0.037925   \n",
       "146043         NaN         0    51.743  ...     0.018001       NaN       NaN   \n",
       "146044         NaN         0   233.211  ...     0.068841  1.684618 -0.094348   \n",
       "\n",
       "          ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
       "0      -0.019761      1  0.413170  0.873555  0.167620  0.161961 -0.042140  \n",
       "1      -0.117832      1  0.157887  0.745139 -0.428957 -0.157888  0.100228  \n",
       "2       0.091206      1  2.231337  1.015131  0.394768  0.063681  0.066348  \n",
       "3       0.017545      1  1.043582  1.026261  0.094822  0.088347 -0.017358  \n",
       "4      -0.466667      0 -1.602508  0.598443 -0.942379 -0.700821  0.130349  \n",
       "...          ...    ...       ...       ...       ...       ...       ...  \n",
       "146040 -0.050591      1  0.103693  0.829680 -0.327178 -0.008179 -0.261606  \n",
       "146041  0.095355      1  0.581796  0.743084 -0.077826  0.000461 -0.296702  \n",
       "146042  0.072050      1 -0.000903  1.063878 -0.002877  0.153133  0.065569  \n",
       "146043       NaN      1  1.109467       NaN  0.000000  0.028804       NaN  \n",
       "146044  0.020573      1  1.154308  0.745399  0.025562  0.026433 -0.240183  \n",
       "\n",
       "[146045 rows x 51 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"uscecchini28.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>sich</th>\n",
       "      <th>insbnk</th>\n",
       "      <th>understatement</th>\n",
       "      <th>option</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>new_p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1009</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312448</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>-0.019761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.873555</td>\n",
       "      <td>0.167620</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>-0.042140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1011</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>-0.211389</td>\n",
       "      <td>-0.117832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157887</td>\n",
       "      <td>0.745139</td>\n",
       "      <td>-0.428957</td>\n",
       "      <td>-0.157888</td>\n",
       "      <td>0.100228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>1017</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>-0.105780</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.231337</td>\n",
       "      <td>1.015131</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>0.066348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>1021</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793068</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>-0.249704</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>1</td>\n",
       "      <td>1.043582</td>\n",
       "      <td>1.026261</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>-0.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>1028</td>\n",
       "      <td>7385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869182</td>\n",
       "      <td>-0.231536</td>\n",
       "      <td>-1.674893</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.602508</td>\n",
       "      <td>0.598443</td>\n",
       "      <td>-0.942379</td>\n",
       "      <td>-0.700821</td>\n",
       "      <td>0.130349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146040</th>\n",
       "      <td>2014</td>\n",
       "      <td>314866</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>262.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>0.560406</td>\n",
       "      <td>0.127217</td>\n",
       "      <td>-0.050591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>-0.327178</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.261606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146041</th>\n",
       "      <td>2014</td>\n",
       "      <td>315318</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1578.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742781</td>\n",
       "      <td>-0.118178</td>\n",
       "      <td>0.031360</td>\n",
       "      <td>0.095355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581796</td>\n",
       "      <td>0.743084</td>\n",
       "      <td>-0.077826</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.296702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146042</th>\n",
       "      <td>2014</td>\n",
       "      <td>316056</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>973.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751129</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>-0.037925</td>\n",
       "      <td>0.072050</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>1.063878</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.153133</td>\n",
       "      <td>0.065569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146043</th>\n",
       "      <td>2014</td>\n",
       "      <td>317260</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.109467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146044</th>\n",
       "      <td>2014</td>\n",
       "      <td>317264</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>233.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>1.684618</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>1</td>\n",
       "      <td>1.154308</td>\n",
       "      <td>0.745399</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>-0.240183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146045 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fyear   gvkey    sich  insbnk  understatement  option  p_aaer  \\\n",
       "0        1990    1009  3460.0       0               0       0     0.0   \n",
       "1        1990    1011  4841.0       0               0       0     0.0   \n",
       "2        1990    1017  3812.0       0               0       0     0.0   \n",
       "3        1990    1021  3861.0       0               0       0     0.0   \n",
       "4        1990    1028  7385.0       0               0       0     0.0   \n",
       "...       ...     ...     ...     ...             ...     ...     ...   \n",
       "146040   2014  314866  8200.0       0               0       0     0.0   \n",
       "146041   2014  315318  2890.0       0               0       0     0.0   \n",
       "146042   2014  316056  3420.0       0               0       0     0.0   \n",
       "146043   2014  317260  4412.0       0               0       0     0.0   \n",
       "146044   2014  317264  4412.0       0               0       0     0.0   \n",
       "\n",
       "        new_p_aaer  misstate       act  ...  soft_assets     ch_cs     ch_cm  \\\n",
       "0              0.0         0    10.047  ...     0.312448  0.095082  0.082631   \n",
       "1              0.0         0     1.247  ...     0.315904  0.188832 -0.211389   \n",
       "2              0.0         0    55.040  ...     0.605342  0.097551 -0.105780   \n",
       "3              0.0         0    24.684  ...     0.793068 -0.005725 -0.249704   \n",
       "4              0.0         0    17.325  ...     0.869182 -0.231536 -1.674893   \n",
       "...            ...       ...       ...  ...          ...       ...       ...   \n",
       "146040         0.0         0   262.600  ...     0.751944  0.560406  0.127217   \n",
       "146041         0.0         0  1578.400  ...     0.742781 -0.118178  0.031360   \n",
       "146042         0.0         0   973.800  ...     0.751129  0.004207 -0.037925   \n",
       "146043         0.0         0    51.743  ...     0.018001  0.000000  0.000000   \n",
       "146044         0.0         0   233.211  ...     0.068841  1.684618 -0.094348   \n",
       "\n",
       "          ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
       "0      -0.019761      1  0.413170  0.873555  0.167620  0.161961 -0.042140  \n",
       "1      -0.117832      1  0.157887  0.745139 -0.428957 -0.157888  0.100228  \n",
       "2       0.091206      1  2.231337  1.015131  0.394768  0.063681  0.066348  \n",
       "3       0.017545      1  1.043582  1.026261  0.094822  0.088347 -0.017358  \n",
       "4      -0.466667      0 -1.602508  0.598443 -0.942379 -0.700821  0.130349  \n",
       "...          ...    ...       ...       ...       ...       ...       ...  \n",
       "146040 -0.050591      1  0.103693  0.829680 -0.327178 -0.008179 -0.261606  \n",
       "146041  0.095355      1  0.581796  0.743084 -0.077826  0.000461 -0.296702  \n",
       "146042  0.072050      1 -0.000903  1.063878 -0.002877  0.153133  0.065569  \n",
       "146043  0.000000      1  1.109467  0.000000  0.000000  0.028804  0.000000  \n",
       "146044  0.020573      1  1.154308  0.745399  0.025562  0.026433 -0.240183  \n",
       "\n",
       "[146045 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[(df['fyear'] >= 1991) & (df['fyear'] <= 2001)]\n",
    "test_df = df[df['fyear'] == 2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67166, 14)\n",
      "(67166,)\n",
      "(5981, 14)\n",
      "(5981,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 37:52]\n",
    "x_test = test[:, 37:52]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost: 1991-2001, 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.3468173305093056  Aupr:  0.010350747548458331  Ndcg:  0.0  Sensitivity:  0.23852657004830924  for depth=  2  estimators =  20\n",
      "AUC:  0.34483781451628714  Aupr:  0.007939414162763388  Ndcg:  0.0  Sensitivity:  0.17788366090927135  for depth=  2  estimators =  30\n",
      "AUC:  0.33753750661881504  Aupr:  0.006069495184083413  Ndcg:  0.0  Sensitivity:  0.11097924982917969  for depth=  2  estimators =  40\n",
      "AUC:  0.5938462179600321  Aupr:  0.014651322866458875  Ndcg:  0.0  Sensitivity:  0.6185278428707907  for depth=  12  estimators =  20\n",
      "AUC:  0.5825219156321705  Aupr:  0.013980141894485565  Ndcg:  0.0  Sensitivity:  0.5916906484146119  for depth=  12  estimators =  30\n",
      "AUC:  0.5942163813221941  Aupr:  0.014541408582806704  Ndcg:  0.011582203012937671  Sensitivity:  0.592438383869653  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from rusboost import RusBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cusboost: 1991-2001, 2003 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6179485105214646  Aupr:  0.020333978982042974  Ndcg:  0.01512410059111566  Sensitivity:  0.6234279554437657  for depth=  2  estimators =  20\n",
      "AUC:  0.6153757525837893  Aupr:  0.01896818247232268  Ndcg:  0.011729143852774506  Sensitivity:  0.5751454981170833  for depth=  2  estimators =  30\n",
      "AUC:  0.6217629091408288  Aupr:  0.018815270355649373  Ndcg:  0.02772639591258839  Sensitivity:  0.5744079179922235  for depth=  2  estimators =  40\n",
      "AUC:  0.6217531034888509  Aupr:  0.017603776641668314  Ndcg:  0.040666295888730775  Sensitivity:  0.6042213966309659  for depth=  12  estimators =  20\n",
      "AUC:  0.6723980702476908  Aupr:  0.018031050417368834  Ndcg:  0.012316808296780965  Sensitivity:  0.630738245900524  for depth=  12  estimators =  30\n",
      "AUC:  0.6380243572395129  Aupr:  0.01721497069697694  Ndcg:  0.014231278356345666  Sensitivity:  0.6097729572938513  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on indicators+raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67166, 42)\n",
      "(67166,)\n",
      "(5981, 42)\n",
      "(5981,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 9:52]\n",
    "x_test = test[:, 9:52]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rusboost: 1991-2001, 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7016703928144182  Aupr:  0.0174441755757427  Ndcg:  0.0  Sensitivity:  0.6176899840477887  for depth=  2  estimators =  20\n",
      "AUC:  0.2274653860485184  Aupr:  0.005645632188443615  Ndcg:  0.0  Sensitivity:  0.3145539906103287  for depth=  2  estimators =  30\n",
      "AUC:  0.7050251514973231  Aupr:  0.020351549034871998  Ndcg:  0.04358354002659847  Sensitivity:  0.606903706498161  for depth=  2  estimators =  40\n",
      "AUC:  0.6796272871683238  Aupr:  0.019197217897951337  Ndcg:  0.0  Sensitivity:  0.6721472748612045  for depth=  12  estimators =  20\n",
      "AUC:  0.7094609833107804  Aupr:  0.020505104381434606  Ndcg:  0.0  Sensitivity:  0.6306468486979142  for depth=  12  estimators =  30\n",
      "AUC:  0.6960995567845306  Aupr:  0.020415732699706462  Ndcg:  0.06031119743240802  Sensitivity:  0.6658772196529634  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from rusboost import RusBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = RusBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cusboost: 1991-2001, 2003 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7158910395952227  Aupr:  0.03778601762169977  Ndcg:  0.055633611071660885  Sensitivity:  0.16060069512754932  for depth=  2  estimators =  20\n",
      "AUC:  0.7311792767351101  Aupr:  0.042508096506897394  Ndcg:  0.0925270432615379  Sensitivity:  0.30317905563347364  for depth=  2  estimators =  30\n",
      "AUC:  0.7366226392892864  Aupr:  0.03999433528113496  Ndcg:  0.07823450567939391  Sensitivity:  0.3298550724637681  for depth=  2  estimators =  40\n",
      "AUC:  0.7587294816732364  Aupr:  0.026033143543372755  Ndcg:  0.06334378031702494  Sensitivity:  0.6866966127072917  for depth=  12  estimators =  20\n",
      "AUC:  0.7437366397991803  Aupr:  0.023916031688165307  Ndcg:  0.0854611057268998  Sensitivity:  0.7021305658000006  for depth=  12  estimators =  30\n",
      "AUC:  0.7323547292659489  Aupr:  0.02484844433029919  Ndcg:  0.07631191859914224  Sensitivity:  0.6666756405079195  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tune for cusboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percentage_to_choose_from_each_cluster=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67166, 28)\n",
      "(67166,)\n",
      "(5981, 28)\n",
      "(5981,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.array(train_df)\n",
    "test = np.array(test_df)\n",
    "x_train = train[:, 9:37]\n",
    "x_test = test[:, 9:37]\n",
    "y_train = train[:, 8]\n",
    "y_test = test[:, 8]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.701325969288698  Aupr:  0.05208438052032662  Ndcg:  0.08975287826902582  Sensitivity:  0.1361611876988335  for depth=  2  estimators =  20\n",
      "AUC:  0.7131025573140359  Aupr:  0.03833143513801246  Ndcg:  0.05789726332020634  Sensitivity:  0.23257074704542996  for depth=  2  estimators =  30\n",
      "AUC:  0.7286714812417879  Aupr:  0.05153673392167279  Ndcg:  0.11107386934940797  Sensitivity:  0.25212267603571953  for depth=  2  estimators =  40\n",
      "AUC:  0.7315739542272166  Aupr:  0.025944167834694835  Ndcg:  0.175042858371351  Sensitivity:  0.7156262781785451  for depth=  12  estimators =  20\n",
      "AUC:  0.7460483222529466  Aupr:  0.025134026293882922  Ndcg:  0.12593436272403927  Sensitivity:  0.7221382974817333  for depth=  12  estimators =  30\n",
      "AUC:  0.773010188072405  Aupr:  0.027329687725959912  Ndcg:  0.06927043290452288  Sensitivity:  0.6911510559564144  for depth=  12  estimators =  40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚成少数样本数量/5个类，每个类选5个代表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.46139759957639587  Aupr:  0.013559538556611414  Ndcg:  0.024369845620875998  Sensitivity:  0.22308454893074636  for depth=  2  estimators =  20\n",
      "AUC:  0.5741650487340904  Aupr:  0.014357153393553649  Ndcg:  0.020594908769652323  Sensitivity:  0.33025661329835937  for depth=  2  estimators =  30\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轮廓系数评估聚类效果 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silhouette score:  0.7638368401930733\n",
      "silhouette score:  0.76479482169199\n",
      "silhouette score:  0.7653440680013068\n",
      "silhouette score:  0.7581347836029769\n",
      "silhouette score:  0.7683766836431736\n",
      "silhouette score:  0.7574386385632482\n",
      "silhouette score:  0.7752425764613862\n",
      "silhouette score:  0.7524348611814686\n",
      "silhouette score:  0.7533231619482416\n",
      "silhouette score:  0.7580682434245501\n",
      "silhouette score:  0.778907195073082\n",
      "silhouette score:  0.7684405955595972\n",
      "silhouette score:  0.7426811970190056\n",
      "silhouette score:  0.7672508542841102\n",
      "silhouette score:  0.768156899697245\n",
      "silhouette score:  0.758655004995363\n",
      "silhouette score:  0.77570244797027\n",
      "silhouette score:  0.7818231172481108\n",
      "silhouette score:  0.7565689134463045\n",
      "silhouette score:  0.7573163447564456\n",
      "AUC:  0.7237294326449765  Aupr:  0.054029582009819485  Ndcg:  0.061596617215299  Sensitivity:  0.20697089471793026  for depth=  2  estimators =  20\n",
      "silhouette score:  0.7695270223509991\n",
      "silhouette score:  0.764648921729599\n",
      "silhouette score:  0.7643767956211851\n",
      "silhouette score:  0.7570621258512528\n",
      "silhouette score:  0.7677256135809494\n",
      "silhouette score:  0.7550372214189575\n",
      "silhouette score:  0.7551674554761146\n",
      "silhouette score:  0.7588457716599708\n",
      "silhouette score:  0.7708998896718326\n",
      "silhouette score:  0.7434161720951639\n",
      "silhouette score:  0.7644689043029662\n",
      "silhouette score:  0.7584308775628742\n",
      "silhouette score:  0.7651863386780567\n",
      "silhouette score:  0.7639861437827922\n",
      "silhouette score:  0.7742458168451212\n",
      "silhouette score:  0.7791588323508754\n",
      "silhouette score:  0.7741947301218363\n",
      "silhouette score:  0.7786318455996267\n",
      "silhouette score:  0.7708665539737102\n",
      "silhouette score:  0.7765747500029976\n",
      "silhouette score:  0.7692909867477712\n",
      "silhouette score:  0.7752930790953905\n",
      "silhouette score:  0.7800151359605281\n",
      "silhouette score:  0.7816954620847562\n",
      "silhouette score:  0.7587008284713237\n",
      "silhouette score:  0.7692272748905156\n",
      "silhouette score:  0.7489525869257213\n",
      "silhouette score:  0.7586994916982778\n",
      "silhouette score:  0.7651351320509436\n",
      "silhouette score:  0.7643920412566313\n",
      "AUC:  0.72887372281383  Aupr:  0.0275468786380243  Ndcg:  0.012855266894581777  Sensitivity:  0.33232764039293866  for depth=  2  estimators =  30\n",
      "silhouette score:  0.769238197130656\n",
      "silhouette score:  0.7588321270530899\n",
      "silhouette score:  0.761303974151873\n",
      "silhouette score:  0.7693392923815557\n",
      "silhouette score:  0.7473523824764328\n",
      "silhouette score:  0.776495868146012\n",
      "silhouette score:  0.7536447137704724\n",
      "silhouette score:  0.7527876557123\n",
      "silhouette score:  0.7677760386711165\n",
      "silhouette score:  0.7796489028087372\n",
      "silhouette score:  0.7584966322888848\n",
      "silhouette score:  0.7651678505311564\n",
      "silhouette score:  0.7407481318210152\n",
      "silhouette score:  0.7450028855468724\n",
      "silhouette score:  0.748899154309891\n",
      "silhouette score:  0.7684957727982495\n",
      "silhouette score:  0.7683894631197452\n",
      "silhouette score:  0.7741920478214352\n",
      "silhouette score:  0.7574225382490641\n",
      "silhouette score:  0.7475383786238374\n",
      "silhouette score:  0.7584014319969753\n",
      "silhouette score:  0.7647094514952232\n",
      "silhouette score:  0.7586151025722095\n",
      "silhouette score:  0.7687288184440444\n",
      "silhouette score:  0.7640043553223232\n",
      "silhouette score:  0.770870568384993\n",
      "silhouette score:  0.746601417041599\n",
      "silhouette score:  0.769146901703514\n",
      "silhouette score:  0.7593405561674353\n",
      "silhouette score:  0.7585947459158301\n",
      "silhouette score:  0.7416514967886689\n",
      "silhouette score:  0.7388867951976871\n",
      "silhouette score:  0.768526350079248\n",
      "silhouette score:  0.7565386754488367\n",
      "silhouette score:  0.7584419084070967\n",
      "silhouette score:  0.7631024726981006\n",
      "silhouette score:  0.7698148968804942\n",
      "silhouette score:  0.7680237574620182\n",
      "silhouette score:  0.7568618453224806\n",
      "silhouette score:  0.7529327985643175\n",
      "AUC:  0.7389563844600027  Aupr:  0.02973480895498352  Ndcg:  0.048751824468879816  Sensitivity:  0.47374914829751574  for depth=  2  estimators =  40\n",
      "silhouette score:  0.7585668496519329\n",
      "silhouette score:  0.769290994506899\n",
      "silhouette score:  0.7644502405823498\n",
      "silhouette score:  0.7594686433938228\n",
      "silhouette score:  0.7573230242571186\n",
      "silhouette score:  0.7582089290950101\n",
      "silhouette score:  0.7766535298351068\n",
      "silhouette score:  0.7660814570545238\n",
      "silhouette score:  0.7556602147093998\n",
      "silhouette score:  0.7584393775185884\n",
      "silhouette score:  0.7644321400222119\n",
      "silhouette score:  0.7754328718869625\n",
      "silhouette score:  0.7758755042475625\n",
      "silhouette score:  0.7747988358739515\n",
      "silhouette score:  0.7680964293246825\n",
      "silhouette score:  0.7597373987243863\n",
      "silhouette score:  0.744720739984608\n",
      "silhouette score:  0.7569069572263704\n",
      "silhouette score:  0.7583223523179731\n",
      "silhouette score:  0.7577567824168373\n",
      "AUC:  0.7401943480222  Aupr:  0.030359620586103687  Ndcg:  0.08805675478995212  Sensitivity:  0.5347983048187097  for depth=  12  estimators =  20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7718769c11e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtprs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCUSBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba_samme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\fraud detection\\cusboost.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mX_undersampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_undersampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchosen_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcus_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_undersampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_undersampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchosen_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\fraud detection\\cus_sampling.py\u001b[0m in \u001b[0;36mcus_sampler\u001b[1;34m(X_train, y_train, number_of_clusters, percentage_to_choose_from_each_cluster)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mclusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajority_class_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"silhouette score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajority_class_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mX_maj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    233\u001b[0m                                     labels=labels, label_freqs=label_freqs)\n\u001b[0;32m    234\u001b[0m     results = zip(*pairwise_distances_chunked(X, reduce_func=reduce_func,\n\u001b[1;32m--> 235\u001b[1;33m                                               **kwds))\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minter_clust_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintra_clust_dists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m             \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py\u001b[0m in \u001b[0;36m_silhouette_reduce\u001b[1;34m(D_chunk, start, labels, label_freqs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         clust_dists[i] += np.bincount(labels, weights=D_chunk[i],\n\u001b[1;32m--> 139\u001b[1;33m                                       minlength=len(label_freqs))\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;31m# intra_index selects intra-cluster distances within clust_dists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from cusboost import CUSBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_dcg(y_pred, y_true, k):\n",
    "    #注意y_pred与y_true必须是一一对应的，并且y_pred越大越接近label=1(用相关性的说法就是，与label=1越相关)\n",
    "    df = pd.DataFrame({\"y_pred\":y_pred, \"y_true\":y_true})\n",
    "    df = df.sort_values(by=\"y_pred\", ascending=False)  # 对y_pred进行降序排列，越排在前面的，越接近label=1\n",
    "    df = df.iloc[0:k, :]  # 取前K个\n",
    "    dcg = (2 ** df[\"y_true\"] - 1) / np.log2(np.arange(1, df[\"y_true\"].count()+1) + 1) # 位置从1开始计数\n",
    "    dcg = np.sum(dcg)\n",
    "    return dcg\n",
    "    \n",
    "def get_ndcg(df, k):\n",
    "    # df包含y_pred和y_true\n",
    "    dcg = get_dcg(df[\"y_pred\"], df[\"y_true\"], k)\n",
    "    idcg = get_dcg(df[\"y_true\"], df[\"y_true\"], k)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "normalization_object = Normalizer()\n",
    "top_auc = 0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "number_of_clusters = 23\n",
    "percentage_to_choose_from_each_cluster = 0.5\n",
    "\n",
    "for depth in range(2, 20, 10):\n",
    "    for estimators in range(20, 50, 10):\n",
    "        current_param_auc = []\n",
    "        current_param_aupr = []\n",
    "        current_param_ndcg = []\n",
    "        current_param_recall = []\n",
    "        tprs = []\n",
    "        classifier = CUSBoostClassifier(depth=depth, n_estimators=estimators)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict_proba_samme(x_test)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "        df_ndcg = pd.DataFrame({\"y_pred\":predictions[:,1], \"y_true\":y_test})\n",
    "        ndcg = get_ndcg(df_ndcg,60)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        current_param_auc.append(auc)\n",
    "        current_param_aupr.append(precision)\n",
    "        current_param_ndcg.append(ndcg)\n",
    "        current_param_recall.append(recall)\n",
    "        \n",
    "        # thresholds阈值表示分类器认为某个样本具有多大概率属于正样本\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        current_mean_auc = np.mean(np.array(current_param_auc))\n",
    "        current_mean_aupr = np.mean(np.array(current_param_aupr))\n",
    "        current_mean_ndcg = np.mean(np.array(current_param_ndcg))\n",
    "        current_mean_recall = np.mean(np.array(current_param_recall))\n",
    "        \n",
    "        print('AUC: ', current_mean_auc, ' Aupr: ', current_mean_aupr, ' Ndcg: ', current_mean_ndcg,' Sensitivity: ', current_mean_recall, ' for depth= ', depth, ' estimators = ', estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
